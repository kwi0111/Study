
import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBClassifier

# 데이터 로드
x, y = load_digits(return_X_y=True)

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(
    x, y, random_state=777, train_size=0.8,
)

scaler = MinMaxScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

parameters = {
    'n_estimators': 1000,
    'learning_rate': 0.01,
    'max_depth': 10,  # 트리 깊이
    'gamma': 0,
    'min_child_weight': 10,
    'subsample': 0.4,
    'colsample_bytree': 0.8,
    'colsample_bylevel': 0.7,
    'colsample_bynode': 1,
    'reg_alpha': 0,
    'reg_lambda': 1,
    'random_state': 3377,
    'verbose': 0,
}

# 모델 정의 및 설정
model = XGBClassifier(**parameters)

# 피처 중요도 계산
model.fit(x_train, y_train)

feature_importances = model.feature_importances_
sorted_indices = np.argsort(feature_importances)[::-1]  # 각 피처의 중요도를 내림차순으로 정렬하여 인덱스를 얻습니다.

# 피처를 하나씩 제거하면서 모델 평가
scores = []
for i in range(len(sorted_indices), 0, -1):
    # 선택된 피처들의 인덱스
    selected_indices = sorted_indices[:i]
    
    # 선택된 피처로 데이터 재구성
    x_train_selected = x_train[:, selected_indices]
    x_test_selected = x_test[:, selected_indices]
    
    # 모델 재훈련
    model.fit(x_train_selected, y_train)
    
    # 모델 평가
    score = model.score(x_test_selected, y_test)
    scores.append((i, score))

# 결과 출력
for i, score in scores:
    print(f"선택된 피처 개수: {i}, 모델 성능: {score}")

'''
선택된 피처 개수: 64, 모델 성능: 0.9388888888888889
선택된 피처 개수: 63, 모델 성능: 0.9361111111111111
선택된 피처 개수: 62, 모델 성능: 0.9444444444444444
선택된 피처 개수: 61, 모델 성능: 0.9388888888888889
선택된 피처 개수: 60, 모델 성능: 0.9388888888888889
선택된 피처 개수: 59, 모델 성능: 0.9416666666666667
선택된 피처 개수: 58, 모델 성능: 0.9388888888888889
선택된 피처 개수: 57, 모델 성능: 0.9444444444444444
선택된 피처 개수: 56, 모델 성능: 0.9444444444444444
선택된 피처 개수: 55, 모델 성능: 0.9416666666666667
선택된 피처 개수: 54, 모델 성능: 0.9472222222222222
선택된 피처 개수: 53, 모델 성능: 0.9416666666666667
선택된 피처 개수: 52, 모델 성능: 0.9388888888888889
선택된 피처 개수: 51, 모델 성능: 0.9416666666666667
선택된 피처 개수: 50, 모델 성능: 0.9388888888888889
선택된 피처 개수: 49, 모델 성능: 0.9388888888888889
선택된 피처 개수: 48, 모델 성능: 0.9416666666666667
선택된 피처 개수: 47, 모델 성능: 0.9388888888888889
선택된 피처 개수: 46, 모델 성능: 0.9472222222222222
선택된 피처 개수: 45, 모델 성능: 0.9444444444444444
선택된 피처 개수: 44, 모델 성능: 0.9388888888888889
선택된 피처 개수: 43, 모델 성능: 0.9416666666666667
선택된 피처 개수: 42, 모델 성능: 0.9388888888888889
선택된 피처 개수: 41, 모델 성능: 0.9361111111111111
선택된 피처 개수: 40, 모델 성능: 0.9333333333333333
선택된 피처 개수: 39, 모델 성능: 0.9416666666666667
선택된 피처 개수: 38, 모델 성능: 0.9444444444444444
선택된 피처 개수: 37, 모델 성능: 0.9361111111111111
선택된 피처 개수: 36, 모델 성능: 0.95
선택된 피처 개수: 35, 모델 성능: 0.9305555555555556
선택된 피처 개수: 34, 모델 성능: 0.9361111111111111
선택된 피처 개수: 33, 모델 성능: 0.9305555555555556
선택된 피처 개수: 32, 모델 성능: 0.9388888888888889
선택된 피처 개수: 31, 모델 성능: 0.9333333333333333
선택된 피처 개수: 30, 모델 성능: 0.9333333333333333
선택된 피처 개수: 29, 모델 성능: 0.9361111111111111
선택된 피처 개수: 28, 모델 성능: 0.9361111111111111
선택된 피처 개수: 27, 모델 성능: 0.9277777777777778
선택된 피처 개수: 26, 모델 성능: 0.9333333333333333
선택된 피처 개수: 25, 모델 성능: 0.9388888888888889
선택된 피처 개수: 24, 모델 성능: 0.9388888888888889
선택된 피처 개수: 23, 모델 성능: 0.9333333333333333
선택된 피처 개수: 22, 모델 성능: 0.9333333333333333
선택된 피처 개수: 21, 모델 성능: 0.9388888888888889
선택된 피처 개수: 20, 모델 성능: 0.9333333333333333
선택된 피처 개수: 19, 모델 성능: 0.9305555555555556
선택된 피처 개수: 18, 모델 성능: 0.9138888888888889
선택된 피처 개수: 17, 모델 성능: 0.9222222222222223
선택된 피처 개수: 16, 모델 성능: 0.9166666666666666
선택된 피처 개수: 15, 모델 성능: 0.9138888888888889
선택된 피처 개수: 14, 모델 성능: 0.9111111111111111
선택된 피처 개수: 13, 모델 성능: 0.875
선택된 피처 개수: 12, 모델 성능: 0.8472222222222222
선택된 피처 개수: 11, 모델 성능: 0.7666666666666667
선택된 피처 개수: 10, 모델 성능: 0.7638888888888888
선택된 피처 개수: 9, 모델 성능: 0.725
선택된 피처 개수: 8, 모델 성능: 0.7055555555555556
선택된 피처 개수: 7, 모델 성능: 0.6944444444444444
선택된 피처 개수: 6, 모델 성능: 0.6333333333333333
선택된 피처 개수: 5, 모델 성능: 0.6277777777777778
선택된 피처 개수: 4, 모델 성능: 0.5138888888888888
선택된 피처 개수: 3, 모델 성능: 0.5083333333333333
선택된 피처 개수: 2, 모델 성능: 0.36944444444444446
선택된 피처 개수: 1, 모델 성능: 0.2388888888888889
'''





